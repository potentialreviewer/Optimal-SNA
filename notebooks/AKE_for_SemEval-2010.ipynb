{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!pip install datasets\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "13_fVDPqQLO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "benchmark = \"SemEval-2010\"\n",
        "dataset = load_dataset(\n",
        "    \"parquet\",\n",
        "    data_files={\n",
        "        \"train\": \"https://huggingface.co/datasets/taln-ls2n/semeval-2010-pre/resolve/refs/convert/parquet/raw/train/0000.parquet\",\n",
        "        \"test\":  \"https://huggingface.co/datasets/taln-ls2n/semeval-2010-pre/resolve/refs/convert/parquet/raw/test/0000.parquet\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "3JAzfB5tQNrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_empty_entries_from_dataset(data):\n",
        "    for split in data.keys():\n",
        "        original_count = len(data[split])\n",
        "\n",
        "        data[split] = data[split].filter(\n",
        "            lambda x: (\n",
        "                x['id'] and\n",
        "                x['lvl-2'] and\n",
        "                x['title'] and\n",
        "                x['abstract'] and\n",
        "                x['keyphrases']\n",
        "            )\n",
        "        )\n",
        "\n",
        "        cleaned_count = len(data[split])\n",
        "\n",
        "        print(f\"[{split}] Before data cleaning: {original_count}\")\n",
        "        print(f\"[{split}] After data cleaning: {cleaned_count}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "dataset = remove_empty_entries_from_dataset(dataset)"
      ],
      "metadata": {
        "id": "17x08V0QQvxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "YI7-oQDLQ0pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Unless otherwise noted in this notebook, the implementations are based on the [Python-based Keyphrase Extraction toolkit (PKE)](https://github.com/boudinfl/pke) by [Boudin (2016)](https://aclanthology.org/C16-2015/), tailored to fit our work."
      ],
      "metadata": {
        "id": "IVAR0eeOCZ1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokenizer import _get_regex_pattern\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
        "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
        "from spacy.util import compile_infix_regex\n",
        "\n",
        "infixes = (\n",
        "    LIST_ELLIPSES\n",
        "    + LIST_ICONS\n",
        "    + [\n",
        "        r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
        "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
        "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
        "        ),\n",
        "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
        "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
        "    ]\n",
        ")\n",
        "\n",
        "infix_re = compile_infix_regex(infixes)\n",
        "nlp.tokenizer.infix_finditer = infix_re.finditer"
      ],
      "metadata": {
        "id": "dGUu-9UoUUJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer as Stemmer\n",
        "\n",
        "all_data = []\n",
        "references = []\n",
        "stemmer = Stemmer('porter')\n",
        "\n",
        "for split in dataset.keys():\n",
        "    for sample in tqdm(dataset[split]):\n",
        "        all_data.append(nlp(sample[\"lvl-2\"]))\n",
        "\n",
        "        sample_keyphrases = []\n",
        "        for keyphrase in sample[\"keyphrases\"]:\n",
        "            tokens = [token.text for token in nlp(keyphrase)]\n",
        "            stems = [stemmer.stem(tok.lower()) for tok in tokens]\n",
        "            sample_keyphrases.append(\" \".join(stems))\n",
        "        references.append(sample_keyphrases)"
      ],
      "metadata": {
        "id": "Z3s845iKRgXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pke import compute_document_frequency\n",
        "from string import punctuation\n",
        "from pke import load_document_frequency_file"
      ],
      "metadata": {
        "id": "Uxn65lIrBhhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_document_frequency(\n",
        "    documents=all_data,\n",
        "    output_file='data/{}.df.gz'.format(benchmark),\n",
        "    language='en',\n",
        "    normalization='stemming',\n",
        "    stoplist=list(punctuation),\n",
        "    n=5\n",
        ")\n",
        "\n",
        "df = load_document_frequency_file(input_file='data/{}.df.gz'.format(benchmark))"
      ],
      "metadata": {
        "id": "pawom_E-Dgxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import logging\n",
        "\n",
        "from pke.base import LoadFile"
      ],
      "metadata": {
        "id": "EPAg8ENdAZcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TF\n",
        "\n",
        "class TF(LoadFile):\n",
        "\n",
        "      def candidate_selection(self, n=3):\n",
        "          self.ngram_selection(n=n)\n",
        "          self.candidate_filtering()\n",
        "\n",
        "      def candidate_weighting(self):\n",
        "        for k, v in self.candidates.items():\n",
        "            self.weights[k] = len(v.surface_forms)\n",
        "            self.weights[k] += (self.candidates[k].offsets[0] * 1e-8)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sxYFEUEsuTDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx"
      ],
      "metadata": {
        "id": "1KTjotqHAbp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TextRank\n",
        "\n",
        "class TextRank1(LoadFile):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TextRank1, self).__init__()\n",
        "        self.graph = nx.Graph()\n",
        "\n",
        "    def candidate_selection(self, pos=None):\n",
        "\n",
        "        if pos is None:\n",
        "            pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "\n",
        "        self.longest_pos_sequence_selection(valid_pos=pos)\n",
        "\n",
        "    def build_word_graph(self, window=2, pos=None):\n",
        "\n",
        "        if pos is None:\n",
        "            pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "\n",
        "        text = [(word, sentence.pos[i] in pos) for sentence in self.sentences\n",
        "                for i, word in enumerate(sentence.stems)]\n",
        "\n",
        "        self.graph.add_nodes_from([word for word, valid in text if valid])\n",
        "\n",
        "        for i, (node1, is_in_graph1) in enumerate(text):\n",
        "\n",
        "            if not is_in_graph1:\n",
        "                continue\n",
        "\n",
        "            for j in range(i + 1, min(i + window, len(text))):\n",
        "                node2, is_in_graph2 = text[j]\n",
        "                if is_in_graph2 and node1 != node2:\n",
        "                    self.graph.add_edge(node1, node2)\n",
        "\n",
        "    def candidate_weighting(self,\n",
        "                            window=2,\n",
        "                            pos=None,\n",
        "                            top_percent=None,\n",
        "                            normalized=False):\n",
        "\n",
        "        if pos is None:\n",
        "            pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "\n",
        "        self.build_word_graph(window=window, pos=pos)\n",
        "\n",
        "        w = nx.pagerank(self.graph, alpha=0.85, tol=0.0001, weight=None)\n",
        "\n",
        "        if top_percent is not None:\n",
        "\n",
        "            nb_nodes = self.graph.number_of_nodes()\n",
        "            to_keep = min(math.floor(nb_nodes * top_percent), nb_nodes)\n",
        "\n",
        "            top_words = sorted(w, key=w.get, reverse=True)\n",
        "\n",
        "            self.longest_keyword_sequence_selection(top_words[:int(to_keep)])\n",
        "\n",
        "        for k in self.candidates.keys():\n",
        "            tokens = self.candidates[k].lexical_form\n",
        "            self.weights[k] = sum([w[t] for t in tokens])\n",
        "            if normalized:\n",
        "                self.weights[k] /= len(tokens)\n",
        "\n",
        "            self.weights[k] += (self.candidates[k].offsets[0]*1e-8)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VkSBBmCyZ_qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The implementation of LMRank [(Giarelies and Karacapilidis, 2023)](https://ieeexplore.ieee.org/document/10179894) is based on [this](https://github.com/NC0DER/LMRank/blob/main/LMRank/model.py) and tailored to fit our work."
      ],
      "metadata": {
        "id": "u4f6nAE2DEp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "f_gBIVsoS-qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import torch\n",
        "import numpy.typing\n",
        "import faiss\n",
        "\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "from difflib import get_close_matches\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import TypeVar, List, Tuple, Any\n",
        "\n",
        "Model = TypeVar('Model')"
      ],
      "metadata": {
        "id": "pGdvAIeLApSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title LMRank\n",
        "\n",
        "class LMRANK():\n",
        "    def __init__(self: LMRANK) -> None:\n",
        "\n",
        "        self.model = SentenceTransformer('all-mpnet-base-v2')\n",
        "        self.text = None\n",
        "        self.doc = None\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_last_seps(string: str, seps: str = '!?.') -> str:\n",
        "        sep_set = set(seps)\n",
        "        for i in range(len(string) - 1, -1, -1):\n",
        "            if string[i - 1] in sep_set:\n",
        "                return string[:i - 1]\n",
        "        return string\n",
        "\n",
        "    @staticmethod\n",
        "    def find_nth_occurence(string: str, substring: str, start: int, end: int, n: int) -> int:\n",
        "\n",
        "        i = string.find(substring, start, end)\n",
        "        while i >= 0 and n > 1:\n",
        "            i = string.find(substring, i + len(substring))\n",
        "            n -= 1\n",
        "        return i\n",
        "\n",
        "    @staticmethod\n",
        "    def create_chunks(string: str, max_token_length: int, token_sep: str = ' ') -> List[str]:\n",
        "\n",
        "        chunk_ranges = []\n",
        "        chunk_start = 0\n",
        "        chunk_end = 0\n",
        "\n",
        "        while chunk_end < len(string):\n",
        "\n",
        "            chunk_start = chunk_end\n",
        "\n",
        "            next_sep_pos = LMRANK.find_nth_occurence(\n",
        "                string, token_sep, chunk_start, len(string),\n",
        "                max_token_length\n",
        "            )\n",
        "\n",
        "            if next_sep_pos == -1:\n",
        "                chunk_end = len(string)\n",
        "            else:\n",
        "                chunk_end = next_sep_pos\n",
        "\n",
        "            chunk_ranges.append((chunk_start, chunk_end))\n",
        "\n",
        "        chunks = [string[i:j] for (i,j) in chunk_ranges]\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def extract_candidate_keyphrases(\n",
        "            self: LMRANK, text: str, sentence_seps: str = '!?.',\n",
        "            deduplicate: bool = True, keep_nouns_adjs: bool = True,\n",
        "        ) -> List[Tuple[str, int]]:\n",
        "\n",
        "        self.text = ' '.join(text.split())\n",
        "\n",
        "        self.doc = nlp(self.text)\n",
        "\n",
        "        candidate_keyphrases = [\n",
        "            (LMRANK.remove_last_seps(chunk.text.lower(), sentence_seps), chunk.start)\n",
        "            for chunk in self.doc.noun_chunks\n",
        "            if chunk.text.lower() not in nlp.Defaults.stop_words\n",
        "            and chunk[0].pos_ not in {'PRON', 'PART'}\n",
        "            and all(\n",
        "                term.pos_ in {'NOUN', 'ADJ'}\n",
        "                if keep_nouns_adjs else True for term in chunk\n",
        "            )\n",
        "            and len(chunk.text) > 2\n",
        "            and not chunk.text[:1].isdigit()\n",
        "            and not any(term.like_url or term.like_email for term in chunk)\n",
        "        ]\n",
        "\n",
        "        candidate_keyphrases = {\n",
        "            key: next(group)[1]\n",
        "            for key, group in groupby(\n",
        "                sorted(candidate_keyphrases, key = itemgetter(0)),\n",
        "                itemgetter(0))\n",
        "        }\n",
        "\n",
        "        if deduplicate:\n",
        "            string_similarity = 0.65\n",
        "\n",
        "            for item in list(candidate_keyphrases):\n",
        "                close_matches = get_close_matches(item, candidate_keyphrases.keys(),\n",
        "                                                  cutoff = 0.65, n = 10)[1:]\n",
        "                for close_match in close_matches:\n",
        "                    if not item.count(' '):\n",
        "                        candidate_keyphrases.pop(item, None)\n",
        "                        break\n",
        "                    elif (len(close_match) > len(item)\n",
        "                            and len(get_close_matches(item, [close_match], n = 1, cutoff = string_similarity))):\n",
        "                        candidate_keyphrases.pop(close_match, None)\n",
        "\n",
        "        return list(candidate_keyphrases.items())\n",
        "\n",
        "    def encode(\n",
        "            self: LMRANK, string_list: List[str],\n",
        "            multi_processing: bool = False, device: str = 'cuda'\n",
        "        ) -> numpy.typing.NDArray[Any]:\n",
        "\n",
        "        model = self.model\n",
        "\n",
        "        if multi_processing:\n",
        "            pool = model.start_multi_process_pool(target_devices = [device])\n",
        "            embeddings = model.encode_multi_process(string_list, pool)\n",
        "            model.stop_multi_process_pool(pool)\n",
        "        else:\n",
        "            embeddings = model.encode(string_list, device = device)\n",
        "        return embeddings\n",
        "\n",
        "    def model_token_length(self: LMRANK) -> int:\n",
        "\n",
        "        model = self.model\n",
        "\n",
        "        return model.max_seq_length\n",
        "\n",
        "    def get_keyphrases_embeddings(\n",
        "            self: LMRANK, candidate_keyphrases: List[Tuple[str, List[int]]]) -> numpy.typing.NDArray[Any]:\n",
        "\n",
        "        embeddings = self.encode([keyphrase for keyphrase, _ in candidate_keyphrases])\n",
        "        return embeddings\n",
        "\n",
        "    def get_document_embedding(self: LMRANK) -> numpy.typing.NDArray[np.float32]:\n",
        "\n",
        "        if len(self.doc) <= self.model_token_length():\n",
        "            document_embedding = self.encode(self.text)\n",
        "        else:\n",
        "            chunks = LMRANK.create_chunks(self.text, self.model_token_length())\n",
        "            document_embedding = np.mean(\n",
        "                self.encode(chunks), axis = 0\n",
        "            )\n",
        "\n",
        "        return document_embedding\n",
        "\n",
        "    def calculate_positional_scores(\n",
        "            self: LMRANK, candidate_keyphrases: List[Tuple[str, int]]\n",
        "        ) -> numpy.typing.NDArray[np.float32]:\n",
        "\n",
        "        scores = np.array([\n",
        "            1 / (position + 1)\n",
        "            for _, position in candidate_keyphrases\n",
        "        ])\n",
        "\n",
        "        e_scores = numpy.exp(scores - np.max(scores))\n",
        "        scores = e_scores / e_scores.sum(axis = 0)\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def LMRank(\n",
        "            self: LMRANK, text: str, sentence_seps: str = '.?!',\n",
        "            deduplicate: bool = False, keep_nouns_adjs: bool = True, positional_feature: bool = True\n",
        "        ) -> List[Tuple[str, float]]:\n",
        "\n",
        "        candidate_keyphrases = self.extract_candidate_keyphrases(\n",
        "            text, sentence_seps, deduplicate, keep_nouns_adjs\n",
        "        )\n",
        "\n",
        "        if not candidate_keyphrases:\n",
        "            return []\n",
        "\n",
        "        embeddings = self.get_keyphrases_embeddings(candidate_keyphrases)\n",
        "        document_embedding = np.atleast_2d(self.get_document_embedding())\n",
        "\n",
        "        unranked_ids = np.array(range(len(embeddings))).astype(np.int64)\n",
        "\n",
        "        embedding_dim = len(embeddings[0])\n",
        "\n",
        "        index = faiss.index_factory(embedding_dim, 'IDMap,Flat', faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "        faiss.normalize_L2(embeddings)\n",
        "\n",
        "        index.add_with_ids(embeddings, unranked_ids)\n",
        "\n",
        "        faiss.normalize_L2(document_embedding)\n",
        "\n",
        "        similarities, ranked_ids = index.search(document_embedding, len(candidate_keyphrases))\n",
        "\n",
        "        if positional_feature:\n",
        "            scores = self.calculate_positional_scores(candidate_keyphrases)\n",
        "\n",
        "            ranked_list = [\n",
        "                (candidate_keyphrases[key_id][0], float(sim * score))\n",
        "                for key_id, sim, score in zip(ranked_ids[0], similarities[0], scores)]\n",
        "\n",
        "        else:\n",
        "            ranked_list = [\n",
        "                (candidate_keyphrases[key_id][0], float(sim))\n",
        "                for key_id, sim in zip(ranked_ids[0], similarities[0])]\n",
        "\n",
        "        # 중복 제거 및 최종 정렬만 수행\n",
        "        seen_stems = {}\n",
        "        for phrase, score in ranked_list:\n",
        "            tokens = [token.text for token in nlp(phrase)]\n",
        "            stems = [stemmer.stem(tok.lower()) for tok in tokens]\n",
        "            stemmed_phrase = \" \".join(stems)\n",
        "\n",
        "            if stemmed_phrase not in seen_stems:\n",
        "                seen_stems[stemmed_phrase] = score\n",
        "            elif score > seen_stems[stemmed_phrase]:\n",
        "                seen_stems[stemmed_phrase] = score\n",
        "\n",
        "        ranked_list = sorted(seen_stems.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return ranked_list"
      ],
      "metadata": {
        "id": "Kz0Iz0aGavqu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pke.unsupervised import *\n",
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "9F6lvovVAzu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = {}\n",
        "outputs2 = {}\n",
        "elapsed_times = {}\n",
        "for model in [TF, TfIdf, KPMiner, YAKE, TextRank1, SingleRank, PositionRank, LMRANK]:\n",
        "    outputs[model.__name__] = []\n",
        "    outputs2[model.__name__] = []\n",
        "\n",
        "    extractor = model()\n",
        "    start = timer()\n",
        "\n",
        "    if model.__name__ == \"KPMiner\":\n",
        "        for i, doc in enumerate(tqdm(all_data)):\n",
        "            extractor.load_document(input=doc, language='en')\n",
        "            extractor.candidate_selection(lasf=3, cutoff=400)\n",
        "\n",
        "            n_dynamic = len(references[i])\n",
        "\n",
        "            extractor.candidate_weighting(df=df)\n",
        "\n",
        "            outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=n_dynamic, stemming=True)])\n",
        "            doc_candidates = dict(extractor.weights)\n",
        "            outputs2[model.__name__].append(doc_candidates)\n",
        "\n",
        "    elif model.__name__ == \"YAKE\":\n",
        "        for i, doc in enumerate(tqdm(all_data)):\n",
        "            extractor.load_document(input=doc, language='en')\n",
        "            extractor.candidate_selection(n=3)\n",
        "\n",
        "            n_dynamic = len(references[i])\n",
        "\n",
        "            use_stems = True\n",
        "            extractor.candidate_weighting(use_stems=use_stems)\n",
        "\n",
        "            outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=n_dynamic, stemming=True)])\n",
        "            doc_candidates = dict(extractor.weights)\n",
        "            outputs2[model.__name__].append(doc_candidates)\n",
        "\n",
        "    elif model.__name__ == \"TextRank1\":\n",
        "        for i, doc in enumerate(tqdm(all_data)):\n",
        "            extractor.load_document(input=doc, language='en')\n",
        "\n",
        "            extractor.candidate_weighting(window=2, pos={'NOUN', 'PROPN', 'ADJ'}, top_percent=0.33)\n",
        "            outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=n_dynamic, stemming=True)])\n",
        "            doc_candidates = dict(extractor.weights)\n",
        "            outputs2[model.__name__].append(doc_candidates)\n",
        "\n",
        "    elif model.__name__ == \"SingleRank\":\n",
        "        for i, doc in enumerate(tqdm(all_data)):\n",
        "            extractor.load_document(input=doc, language='en')\n",
        "            extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ'})\n",
        "\n",
        "            extractor.candidate_weighting(window=10, pos={'NOUN', 'PROPN', 'ADJ'})\n",
        "            outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=n_dynamic, stemming=True)])\n",
        "            doc_candidates = dict(extractor.weights)\n",
        "            outputs2[model.__name__].append(doc_candidates)\n",
        "\n",
        "    elif model.__name__ == \"PositionRank\":\n",
        "        for i, doc in enumerate(tqdm(all_data)):\n",
        "            extractor.load_document(input=doc, language='en')\n",
        "            extractor.candidate_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\", maximum_word_number=3)\n",
        "\n",
        "            extractor.candidate_weighting(window=10, pos={'NOUN', 'PROPN', 'ADJ'})\n",
        "            outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=n_dynamic, stemming=True)])\n",
        "            doc_candidates = dict(extractor.weights)\n",
        "            outputs2[model.__name__].append(doc_candidates)\n",
        "\n",
        "    elif model.__name__ == \"LMRANK\":\n",
        "\n",
        "        for i, text in enumerate(tqdm(all_data)):\n",
        "            n_dynamic = len(references[i])\n",
        "\n",
        "            text = str(text)\n",
        "            ranked_list = extractor.LMRank(text=text)\n",
        "\n",
        "            outputs[model.__name__].append([u for u, v in ranked_list[:n_dynamic]])\n",
        "            outputs2[model.__name__].append({u: v for u, v in ranked_list})\n",
        "\n",
        "    else:\n",
        "        for i, doc in enumerate(tqdm(all_data)):\n",
        "            extractor.load_document(input=doc, language='en')\n",
        "            extractor.candidate_selection(n=3)\n",
        "\n",
        "            n_dynamic = len(references[i])\n",
        "\n",
        "            if model.__name__ == \"TfIdf\":\n",
        "                extractor.candidate_weighting(df=df)\n",
        "            else:\n",
        "                extractor.candidate_weighting()\n",
        "            outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=n_dynamic, stemming=True)])\n",
        "            doc_candidates = dict(extractor.weights)\n",
        "            outputs2[model.__name__].append(doc_candidates)\n",
        "\n",
        "    end = timer()\n",
        "    elapsed_times[model.__name__] = end - start"
      ],
      "metadata": {
        "id": "ALeT9eO2R9I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_exact(top_N_candidates, references, cutoff=None):\n",
        "    if cutoff is None:\n",
        "        cutoff = len(references)\n",
        "    cutoff = min(cutoff, len(top_N_candidates))\n",
        "    P = len(set(top_N_candidates[:cutoff]) & set(references)) / len(top_N_candidates[:cutoff])\n",
        "    R = len(set(top_N_candidates[:cutoff]) & set(references)) / len(references)\n",
        "    F = (2 * P * R) / (P + R) if (P + R) > 0 else 0\n",
        "    return (P, R, F)\n",
        "\n",
        "def split_into_tokens(phrases):\n",
        "    tokens = set()\n",
        "    for phrase in phrases:\n",
        "        tokens.update(phrase.split())\n",
        "    return tokens\n",
        "\n",
        "def evaluate_partial(top_N_candidates, references, cutoff=None):\n",
        "    if cutoff is None:\n",
        "        cutoff = len(references)\n",
        "    cutoff = min(cutoff, len(top_N_candidates))\n",
        "\n",
        "    predicted_tokens = split_into_tokens(top_N_candidates[:cutoff])\n",
        "    reference_tokens = split_into_tokens(references)\n",
        "\n",
        "    intersection = len(predicted_tokens & reference_tokens)\n",
        "\n",
        "    P = intersection / len(predicted_tokens) if predicted_tokens else 0\n",
        "    R = intersection / len(reference_tokens) if reference_tokens else 0\n",
        "    F = (2 * P * R) / (P + R) if (P + R) > 0 else 0\n",
        "    return (P, R, F)\n",
        "\n",
        "def evaluate_harmonic(F1, pF1):\n",
        "    return (2 * F1 * pF1) / (F1 + pF1) if (F1 + pF1) > 0 else 0"
      ],
      "metadata": {
        "id": "dt29HszEuqmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "NZy48DoQHWo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"## Benchmarking on {}\".format(benchmark))\n",
        "print(\"| Model       | it/s |     F    |   pF    |    hF    |\")\n",
        "print(\"| :---------- | ----:| -------: | ------: | -------: |\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for model in outputs:\n",
        "    scores_exact = []\n",
        "    scores_partial = []\n",
        "    scores_harmonic = []\n",
        "\n",
        "    for i, output in enumerate(outputs[model]):\n",
        "        if not output:\n",
        "            P_exact, R_exact, F_exact = (0, 0, 0)\n",
        "            P_partial, R_partial, F_partial = (0, 0, 0)\n",
        "            hF1 = 0\n",
        "        else:\n",
        "            P_exact, R_exact, F_exact = evaluate_exact(output, references[i], cutoff=None)\n",
        "            P_partial, R_partial, F_partial = evaluate_partial(output, references[i], cutoff=None)\n",
        "            hF1 = evaluate_harmonic(F_exact, F_partial)\n",
        "\n",
        "        scores_exact.append((P_exact, R_exact, F_exact))\n",
        "        scores_partial.append((P_partial, R_partial, F_partial))\n",
        "        scores_harmonic.append(hF1)\n",
        "\n",
        "    P_exact, R_exact, F_exact = np.mean(scores_exact, axis=0)\n",
        "    P_partial, R_partial, F_partial = np.mean(scores_partial, axis=0)\n",
        "    hF1_mean = np.mean(scores_harmonic)\n",
        "\n",
        "    print(\"| {}  | {:.5f} | {:.5f} | {:.5f} | {:.5f} |\".format(\n",
        "        model,\n",
        "        len(all_data) / elapsed_times[model],\n",
        "        F_exact,\n",
        "        F_partial,\n",
        "        hF1_mean\n",
        "    ))\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model,\n",
        "        \"F\": F_exact,\n",
        "        \"pF\": F_partial,\n",
        "        \"hF\": hF1_mean\n",
        "    })"
      ],
      "metadata": {
        "id": "eMmQXiQTSCA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GDm9aCS5A_uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "eyLPPZypuvl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results"
      ],
      "metadata": {
        "id": "R90joLNxSFOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "1tQWfWfsBCJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"SemEval-2010_results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(df_results, f)"
      ],
      "metadata": {
        "id": "-7Zrr_x3zK3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats"
      ],
      "metadata": {
        "id": "0nYrb_XmBD_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_outputs(outputs2):\n",
        "    outputs3 = {}\n",
        "\n",
        "    for method, documents in outputs2.items():\n",
        "        normalized_documents = []\n",
        "\n",
        "        for doc in documents:\n",
        "            if not doc:\n",
        "                normalized_documents.append({})\n",
        "                continue\n",
        "\n",
        "            keys = list(doc.keys())\n",
        "            values = list(doc.values())\n",
        "\n",
        "            ranks = scipy.stats.rankdata(values, method=\"dense\")\n",
        "            rank_dict = dict(zip(keys, ranks))\n",
        "\n",
        "            x_min = min(ranks)\n",
        "            x_max = max(ranks)\n",
        "\n",
        "            if x_max == x_min:\n",
        "                norm_doc = {k: 0.0 for k in doc}\n",
        "\n",
        "            elif method in [\"TF\", \"TfIdf\", \"KPMiner\", \"TextRank1\", \"SingleRank\", \"PositionRank\", \"LMRANK\"]:\n",
        "                norm_doc = {k: float((rank_dict[k] - x_min) / (x_max - x_min)) for k in doc}\n",
        "\n",
        "            elif method in [\"YAKE\"]:\n",
        "                norm_doc = {k: float((x_max - rank_dict[k]) / (x_max - x_min)) for k in doc}\n",
        "\n",
        "            normalized_documents.append(norm_doc)\n",
        "\n",
        "        outputs3[method] = normalized_documents\n",
        "\n",
        "    return outputs3"
      ],
      "metadata": {
        "id": "fZSMK2yo0bSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs3 = normalize_outputs(outputs2)"
      ],
      "metadata": {
        "id": "7VSYZx-p0m0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "HWlBJq11BJ9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_DTM(outputs, outputs3, method, zeta=0.5, top_k=50):\n",
        "\n",
        "    docs_phrases = outputs[method]\n",
        "    docs_scores = outputs3[method]\n",
        "\n",
        "    k_score = round(top_k * zeta)\n",
        "    k_freq = top_k - k_score\n",
        "\n",
        "    score_sum = defaultdict(float)\n",
        "    for doc_scores in docs_scores:\n",
        "        for phrase, score in doc_scores.items():\n",
        "            score_sum[phrase] += score\n",
        "    top_score_ranked = sorted(score_sum.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    freq_counter = Counter()\n",
        "    for phrases in docs_phrases:\n",
        "        freq_counter.update(phrases)\n",
        "    most_common = freq_counter.most_common()\n",
        "\n",
        "    freq_terms = []\n",
        "    last_freq = None\n",
        "    for i, (phrase, freq) in enumerate(most_common):\n",
        "        if i < k_freq:\n",
        "            freq_terms.append((phrase, freq))\n",
        "            last_freq = freq\n",
        "        elif freq == last_freq:\n",
        "            freq_terms.append((phrase, freq))\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    if len(freq_terms) > k_freq:\n",
        "        target_freq = freq_terms[k_freq - 1][1]\n",
        "        tie_start_idx = next(i for i, (_, freq) in enumerate(freq_terms) if freq == target_freq)\n",
        "        tied_candidates = [x for x in freq_terms[tie_start_idx:] if x[1] == target_freq]\n",
        "\n",
        "        tied_candidates_sorted = sorted(\n",
        "            tied_candidates,\n",
        "            key=lambda x: score_sum.get(x[0], 0),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        num_needed = k_freq - tie_start_idx\n",
        "        freq_terms = freq_terms[:tie_start_idx] + tied_candidates_sorted[:num_needed]\n",
        "\n",
        "    top_freq_terms = [phrase for phrase, _ in freq_terms]\n",
        "\n",
        "    selected_terms = set(top_freq_terms)\n",
        "    final_phrases = list(top_freq_terms)\n",
        "\n",
        "    for phrase, _ in top_score_ranked:\n",
        "        if phrase not in selected_terms:\n",
        "            final_phrases.append(phrase)\n",
        "            selected_terms.add(phrase)\n",
        "        if len(final_phrases) == top_k:\n",
        "            break\n",
        "\n",
        "    matrix = []\n",
        "    for doc_scores in docs_scores:\n",
        "        row = [doc_scores.get(term, 0) for term in final_phrases]\n",
        "        matrix.append(row)\n",
        "\n",
        "    df_matrix = pd.DataFrame(matrix, columns=final_phrases)\n",
        "    return df_matrix"
      ],
      "metadata": {
        "id": "cvMqhD7Q1AvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_all_dtms(outputs, outputs3, dataset_name, method_list, zeta_list=[0.25, 0.5, 0.75], top_k=50):\n",
        "    dtm_dict = {}\n",
        "\n",
        "    for method in method_list:\n",
        "        for zeta in zeta_list:\n",
        "            df = build_DTM(outputs, outputs3, method, zeta=zeta, top_k=top_k)\n",
        "\n",
        "            zeta_str = str(zeta).replace('.', '_')\n",
        "            var_name = f\"{dataset_name}_{method}_zeta{zeta_str}\"\n",
        "\n",
        "            dtm_dict[var_name] = df\n",
        "\n",
        "    with open(f\"{dataset_name}_dtm_dict.pkl\", \"wb\") as f:\n",
        "        pickle.dump(dtm_dict, f)\n",
        "\n",
        "    return dtm_dict"
      ],
      "metadata": {
        "id": "7uE0DQSM1jyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"SemEval-2010\"\n",
        "method_list = [\"TF\", \"TfIdf\", \"KPMiner\", \"YAKE\", \"TextRank1\", \"SingleRank\", \"PositionRank\", \"LMRANK\"]\n",
        "dtms = save_all_dtms(outputs, outputs3, dataset_name, method_list)"
      ],
      "metadata": {
        "id": "3OhCtVwq2ugP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"SemEval-2010_dtm_dict.pkl\", \"rb\") as f:\n",
        "    DTM_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "fo1UkRAS2vbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DTM_dict.keys())"
      ],
      "metadata": {
        "id": "sNWvrZxpTTpL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}