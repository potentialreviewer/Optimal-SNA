{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install igraph"
      ],
      "metadata": {
        "id": "EGsgipJDeD2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "20_majtxeCUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "random.seed(2025)\n",
        "np.random.seed(2025)\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import glob\n",
        "import networkx as nx\n",
        "import igraph as ig\n",
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)"
      ],
      "metadata": {
        "id": "_pYMbwcILjdC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leiden(G, seed=2025, resolution=1.0, weight=\"weight\", objective=\"modularity\", beta=0.1, n_iterations=200):\n",
        "    random.seed(seed)\n",
        "\n",
        "    nodes = sorted(G.nodes())\n",
        "    node_to_index = {n: i for i, n in enumerate(nodes)}\n",
        "    edges = list(G.edges(data=True))\n",
        "    g = ig.Graph(n=len(G.nodes()), edges=[(node_to_index[u], node_to_index[v]) for u, v, _ in edges])\n",
        "    g.es[\"weight\"] = [similarity[\"weight\"] for _, _, similarity in edges]\n",
        "\n",
        "    partition = g.community_leiden(objective_function=objective, weights=g.es[\"weight\"], resolution=resolution, beta=beta, n_iterations=n_iterations)\n",
        "    communities = [set(nodes[v] for v in community) for community in partition]\n",
        "\n",
        "    return communities"
      ],
      "metadata": {
        "id": "cfRUD6gJLnPU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_algorithm(G, algorithm, seed=2025, n_trials=50):\n",
        "    def objective(trial):\n",
        "        if algorithm == \"CNM\":\n",
        "            communities = list(nx.algorithms.community.greedy_modularity_communities(G, weight=\"weight\"))\n",
        "            return nx.algorithms.community.modularity(G, communities, weight=\"weight\")\n",
        "\n",
        "        elif algorithm == \"Louvain\":\n",
        "            communities = list(nx.algorithms.community.louvain_communities(G, seed=seed, weight=\"weight\"))\n",
        "            return nx.algorithms.community.modularity(G, communities, weight=\"weight\")\n",
        "\n",
        "        elif algorithm == \"Leiden\":\n",
        "            beta = trial.suggest_float(\"beta\", 0.1, 10, log=True)\n",
        "            communities = list(leiden(G, seed=seed, weight=\"weight\", objective=\"modularity\", beta=beta, n_iterations=200))\n",
        "            return nx.algorithms.community.modularity(G, communities, weight=\"weight\")\n",
        "\n",
        "        elif algorithm == \"FLPA\":\n",
        "            communities = list(nx.algorithms.community.fast_label_propagation_communities(G, seed=seed, weight=\"weight\"))\n",
        "            return nx.algorithms.community.modularity(G, communities, weight=\"weight\")\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    best_trial = study.best_trial\n",
        "    return best_trial.value, best_trial.params"
      ],
      "metadata": {
        "id": "A9ODRfsXMcWz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_graph_dict_optuna(graph_dict, dataset_name, seed=2025, n_trials=50):\n",
        "    records = []\n",
        "    excluded_methods = {\"Euclidean\", \"Manhattan\", \"DMD\"}\n",
        "    included_methods = [\"CNM\", \"Louvain\", \"Leiden\", \"FLPA\"]\n",
        "\n",
        "    for ake_method in graph_dict[dataset_name]:\n",
        "        for zeta in graph_dict[dataset_name][ake_method]:\n",
        "            for edge_method, G in graph_dict[dataset_name][ake_method][zeta].items():\n",
        "                if edge_method in excluded_methods:\n",
        "                    continue\n",
        "\n",
        "                for algorithm in included_methods:\n",
        "                    best_score, best_params = tune_algorithm(G, algorithm, seed=seed, n_trials=n_trials)\n",
        "                    parameters = [f\"{k}={v}\" for k, v in best_params.items()]\n",
        "\n",
        "                    records.append({\n",
        "                        \"Dataset\": dataset_name,\n",
        "                        \"AKE Method\": ake_method,\n",
        "                        \"Zeta\": zeta,\n",
        "                        \"Edge Measure\": edge_method,\n",
        "                        \"Algorithm\": algorithm,\n",
        "                        \"Modularity\": best_score,\n",
        "                        \"Parameters\": parameters\n",
        "                    })\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    modularity_values = df[\"Modularity\"].values\n",
        "    modularity_values = np.where(modularity_values < 0, 0, modularity_values)\n",
        "    df[\"Modularity\"] = modularity_values\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "XKfA6GMDNCTj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request"
      ],
      "metadata": {
        "id": "k-4HpAv9Tv6C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/potentialreviewer/Optimal-SNA/main/data/\"\n",
        "\n",
        "files = [\n",
        "    \"SemEval-2010_graph_dict.pkl\",\n",
        "    \"NUS_graph_dict.pkl\",\n",
        "    \"Inspec_graph_dict.pkl\",\n",
        "    \"KDD_graph_dict.pkl\",\n",
        "    \"WWW_graph_dict.pkl\",\n",
        "    \"SemEval-2017_graph_dict.pkl\",\n",
        "    \"DUC-2001_graph_dict.pkl\",\n",
        "    \"500N-KP-Crowd_graph_dict.pkl\"\n",
        "\n",
        "]\n",
        "\n",
        "for f in files:\n",
        "    urllib.request.urlretrieve(base_url + f, f)"
      ],
      "metadata": {
        "id": "7s081F0wT6l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = []\n",
        "\n",
        "for path in glob.glob(\"*_graph_dict.pkl\"):\n",
        "    dataset_name = path.split(\"_graph_dict.pkl\")[0]\n",
        "    with open(path, \"rb\") as f:\n",
        "        graph_dict = pickle.load(f)\n",
        "\n",
        "    df = evaluate_graph_dict_optuna(graph_dict, dataset_name, seed=2025, n_trials=50)\n",
        "    all_results.append(df)\n",
        "\n",
        "results_df = pd.concat(all_results, ignore_index=True)\n",
        "results_df['Zeta'] = results_df['Zeta'].str.replace('_', '.', regex=False).astype(float)"
      ],
      "metadata": {
        "id": "4ViDI1vPNEta"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files2 = [\n",
        "    \"SemEval-2010_percolation_results.pkl\",\n",
        "    \"NUS_percolation_percolation_results.pkl\",\n",
        "    \"Inspec_percolation_results.pkl\",\n",
        "    \"KDD_percolation_results.pkl\",\n",
        "    \"WWW_percolation_results.pkl\",\n",
        "    \"SemEval-2017_percolation_results.pkl\",\n",
        "    \"DUC-2001_percolation_results.pkl\",\n",
        "    \"500N-KP-Crowd_percolation_results.pkl\"\n",
        "\n",
        "]\n",
        "\n",
        "for f2 in files2:\n",
        "    urllib.request.urlretrieve(base_url + f2, f2)"
      ],
      "metadata": {
        "id": "TFx7quxuQHYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "AzjPkWMJRzrg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percolation_dataset = pd.concat([pd.read_pickle(path) for path in glob.glob('*_percolation_results.pkl')], ignore_index=True)\n",
        "percolation_dataset.drop(columns=['All Traces'], inplace=True)\n",
        "percolation_dataset['Zeta'] = percolation_dataset['Zeta'].str.replace('_', '.', regex=False).astype(float)\n",
        "percolation_dataset = shuffle(percolation_dataset, random_state=2025).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "8ivdguY6QHiy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percolation_subset = percolation_dataset[\n",
        "    [\"Dataset\", \"AKE Method\", \"Zeta\", \"Edge Measure\", \"RI\", \"Isolated Nodes\", \"Edge Count\"]\n",
        "]\n",
        "\n",
        "new_results_df = results_df.merge(\n",
        "    percolation_subset,\n",
        "    on=[\"Dataset\", \"AKE Method\", \"Zeta\", \"Edge Measure\"],\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "aP6xgIwiQ0_J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "community_detection_dataset = new_results_df"
      ],
      "metadata": {
        "id": "9LCwrGSRQ5Y_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "community_detection_dataset"
      ],
      "metadata": {
        "id": "z1pcOCAAd8Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Community_Detection.pkl\", \"wb\") as f:\n",
        "    pickle.dump(community_detection_dataset, f)"
      ],
      "metadata": {
        "id": "zMh3rptQQ7mp"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}